{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix\n",
    "\n",
    "Here I am just storing some things I am taking out of my assignment to reduce the size.\n",
    "I want to keep them as a reference point though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[W3resource](https://www.w3resource.com/numpy/index.php) describes NumPy as the \n",
    "> fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more. \n",
    "\n",
    "NumPy's main data structure is the **ndarray** - a homogenuous multidimensional array object. NumPy has many mathematical functions and algorithms for doing very fast numerical operations on arrays. Batch operations avoid the need to use loops by working on entire arrays of data at a time using **vectorisation** but using similar syntax to working with scalars.\n",
    "An [array](https://en.wikipedia.org/wiki/Array_data_structure) is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key. Python itself does not have an array data structure so the NumPy library allows for the creation and manipulatation of arrays of numbers. Although matrix operations are possible in Python, they are quite inefficient when compared to NumPy's capabilities on large multi-dimensional arrays of numbers and such matrix type operations are very commonly used when analysing data and for other computing purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Simplerandomdata'></a>\n",
    "### Simple random data functions\n",
    "- `rand(d0, d1, …, dn)`\tRandom values in a given shape.\n",
    "- `randn(d0, d1, …, dn)`\tReturn a sample (or samples) from the “standard normal” distribution.\n",
    "- `randint(low[, high, size, dtype])`\tReturn random integers from low (inclusive) to high (exclusive).\n",
    "- `random_integers(low[, high, size])`\tRandom integers of type np.int between low and high, inclusive.\n",
    "- `random_sample([size])`\tReturn random floats in the half-open interval `[0.0, 1.0)`.\n",
    "- `random([size])`\tReturn random floats in the half-open interval `[0.0, 1.0)`.\n",
    "- `ranf([size])`\tReturn random floats in the half-open interval `[0.0, 1.0)`.\n",
    "- `sample([size])`\tReturn random floats in the half-open interval `[0.0, 1.0)`.\n",
    "- `choice(a[, size, replace, p])`\tGenerates a random sample from a given 1-D array\n",
    "- `bytes(length)`\tReturn random bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Probability Distributions\n",
    "\n",
    "see https://machinelearningmastery.com/discrete-probability-distributions-for-machine-learning/\n",
    "\n",
    ">A discrete random variable is a random variable that can have one of a finite set of specific outcomes. The two types of discrete random variables most commonly used in machine learning are binary and categorical.\n",
    "\n",
    "- A **binary random variable** is a discrete random variable where the finite set of outcomes is in {0, 1}. \n",
    "- A **categorical random variable** is a discrete random variable where the finite set of outcomes is in {1, 2, …, K}, where K is the total number of unique outcomes.\n",
    "\n",
    "Each outcome or event for a discrete random variable has a probability.\n",
    "The probability mass function summarises a discrete probablity distribution which relates events for a discrete random variable with their probabilities of occurring.\n",
    "\n",
    "A Probability Mass Function (PMF) returns the probability of a given outcome.\n",
    "A Cumulative Distribution Function (CDF) returns the probability of a value less than or equal to a given outcome.\n",
    "A Percent-Point Function (PPF) returns a discrete value that is less than or equal to the given probability.\n",
    "\n",
    "The most common discrete probability distributions are the Bernoulli and Multinoulli distributions for binary and categorical discrete random variables respectively, and the Binomial and Multinomial distributions that generalize each to multiple independent trials.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Bernoulli distribution\n",
    "\n",
    "A bit of background on the Bernoulli distribution which tis related to the Binomial Distribution\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bernoulli_distribution\n",
    ">In probability theory and statistics, the Bernoulli distribution, named after Swiss mathematician Jacob Bernoulli\n",
    "is the discrete probability distribution of a random variable which takes the value 1 with probability \n",
    "$p$ and the value 0 with probability ${\\displaystyle q=1-p,}$ that is, the probability distribution of any single experiment that asks a yes–no question.\n",
    "A Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, \"success\" and \"failure\", in which the probability of success is the same every time the experiment is conducted.\n",
    "\n",
    "The **Bernoulli distribution** is a special case of the binomial distribution where a single trial is conducted (n=1) and where the outcome is binary, that is either 0 or 1.\n",
    "\n",
    "$x in {0, 1}$\n",
    "A **Bernoulli trial** is an experiment whose outcome follows a Bernoulli distribution such as a single flip of a coin that may have a heads (0) or a tails (1) outcome.\n",
    "\n",
    ">A common example of a Bernoulli trial in machine learning might be a binary classification of a single example as the first class (0) or the second class (1).\n",
    "The distribution can be summarized by a single variable p that defines the probability of an outcome 1. Given this parameter, the probability for each event can be calculated as follows:\n",
    "\n",
    "$P(x=1) = p$\n",
    "$P(x=0) = 1 – p$\n",
    "In the case of flipping a fair coin, the value of p would be 0.5, giving a 50% probability of each outcome.\n",
    "\n",
    "A **Bernoulli process** is the repetition of multiple independent Bernoulli trials. It's outcomes follow a **Binomial** distribution. The Bernoulli distribution can be considered as a Binomial distribution with a single trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution is the probability of a success or failure outcome in an experiment that is repeated many times. A binomial experiment has only two (bi) possible outcomes such as heads or tails, true or false etc. One of these outcomes can be called a **success** and the other a **failure**. The probability of success (P) is the same on every trial\n",
    "A single coin flip is an example of an experiment with a binary outcome. \n",
    "\n",
    "A **binomial experiment** consists of a number $n$ of repeated identical **Bernoulli** trials \n",
    "- where there are only two possible outcomes, success or failure \n",
    "- the probability of success (p) is constant (the same in every trial)\n",
    "- the $n$ trials are independent - outcome of one trial does not affect the outcome of another trial.\n",
    "- The binomial random variable x is the number of $S$’s in n trials.\n",
    "\n",
    "The outcome of a binomial experiment is a **binomial random variable**.\n",
    "**Binomial probability** is the probability that a binomial random variable assumes a specific value. \n",
    "-b(x,n,P): Binomial probability  - the probability that an n-trial binomial experiment results in exactly x successes.\n",
    "**Binomial distribution** is the probability distribution of a binomial random variable.\n",
    "\n",
    "### The binomial distribution has the following properties:\n",
    "- The mean of the distribution is equal to $n*P$\n",
    "- The variance $\\sigma^2$ is $n*P*(1-p)$\n",
    "- the standard deviation $sqrt(n*P*(1-p))$\n",
    "\n",
    "\n",
    "***\n",
    "The [binomial distribution](http://mathworld.wolfram.com/BinomialDistribution.html) gives the discrete probability distribution $P_p(n|N)$ of obtaining exactly n successes out of N Bernoulli trials (where the result of each Bernoulli trial is true with probability $p$ and false with probability $q=1-p$).\n",
    "\n",
    "The binomial distribution is the probability distribution of a sequence of experiments where each experiment produces a binary outcome and where each of the outcomes is independent of all the others.\n",
    "\n",
    "$n$ is the number of times the experiment is run while $p$ is the probability of a specific outcome such as heads. \n",
    "The results from performing the same set of experiments, such as repeatedly flipping a coin a number of times and the number of heads observed across all the sets of experiments follows the binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### The Bernoulli distribution\n",
    "\n",
    "A Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, \"success\" and \"failure\", in which the probability of success is the same every time the experiment is conducted.\n",
    "A **Bernoulli process** is the repetition of multiple independent Bernoulli trials. It's outcomes follow a **Binomial** distribution. The Bernoulli distribution can be considered as a Binomial distribution with a single trial (n=1).\n",
    "\n",
    "A Bernoulli distribution has only two possible outcomes, 1 (success) and 0 (failure), and a single trial, for example, a single coin toss. A random variable X which has a Bernoulli distribution can take value 1 with the probability of success, p, and the value 0 with the probability of failure, q or 1−p. The probabilities of success and failure need not be equally likely. \n",
    "\n",
    ">A common example of a Bernoulli trial in machine learning might be a binary classification of a single example as the first class (0) or the second class (1).\n",
    "The distribution can be summarized by a single variable p that defines the probability of an outcome 1. Given this parameter, the probability for each event can be calculated as follows:\n",
    "\n",
    "$P(x=1) = p$\n",
    "$P(x=0) = 1 – p$\n",
    "In the case of flipping a fair coin, the value of p would be 0.5, giving a 50% probability of each outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The [binomial distribution](http://mathworld.wolfram.com/BinomialDistribution.html) gives the discrete probability distribution $P_p(n|N)$ of obtaining exactly n successes out of N Bernoulli trials (where the result of each Bernoulli trial is true with probability $p$ and false with probability $q=1-p$).\n",
    "\n",
    "The binomial distribution is the probability distribution of a sequence of experiments where each experiment produces a binary outcome and where each of the outcomes is independent of all the others.\n",
    "\n",
    "$n$ is the number of times the experiment is run while $p$ is the probability of a specific outcome such as heads. \n",
    "The results from performing the same set of experiments, such as repeatedly flipping a coin a number of times and the number of heads observed across all the sets of experiments follows the binomial distribution.\n",
    "\n",
    "\n",
    "***\n",
    "Using `numpy.random.binomial`, samples are drawn from a binomial distribution with specified parameters, $n$ trials and $p$ probability of success where $n$ an integer >= 0 and $p$ is in the interval $[0,1]$. \n",
    "\n",
    "The function takes an integer for $n$ the number of trials and a float for the $p$ for the probability of success. $p$ must be between 0 and 1. You can also specify the number of samples to be drawn using the size parameter. The function returns an array of samples drawn from the binomial distribution based on the $n$ and $p$ and $size$ parameters given to the function.\n",
    "\n",
    ">Drawn samples from the parameterized binomial distribution, where each sample is equal to the number of successes over the n trials.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Binomial Distribution - Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution)the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own boolean-valued outcome: success/yes/true/one (with probability p) or failure/no/false/zero (with probability q = 1 − p). A single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. \n",
    "\n",
    "The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a hypergeometric distribution, not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson\n",
    "\n",
    "[The Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution), named after French mathematician Siméon Denis Poisson, is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event. The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume. \n",
    "\n",
    "It was originally developed by Siméon Denis Poisson in the 1830's in France to look at the pattern of wrongful convictions in a year.\n",
    "\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459) has a good overview of the Poisson Distribution and Poisson Process.\n",
    "\n",
    "> A Poisson Distribution gives the probability of a number of events in an interval generated by a Poisson process. The Poisson distribution is defined by the rate parameter, λ, which is the expected number of events in the interval (events/interval * interval length) and the highest probability number of events. We can also use the Poisson Distribution to find the waiting time between events. Even if we arrive at a random time, the average waiting time will always be the average time between events.\n",
    "\n",
    "A poisson process is a model for a series of discrete events where the average time between events is known but the exact timing of events is random or stochastic. While poisson processes are generally associated with time they don't have to be. \n",
    "\n",
    "The Poisson Process is the model used for describing randomly occurring events while the Poisson Distribution is used for things like finding the probability of a number of events in a time period or finding the probability of waiting some time until the next event.\n",
    "The Poisson Distribution probability mass function gives the probability of observing k events in a time period given the length of the period and the average events per time.\n",
    "\n",
    "The poisson probability distribution function takes one parameter which is lamda $\\lambda$ or the rate parameter which is a function of both the average events per time and the length of the time period  or the expected number of events in an interval.\n",
    "\n",
    "As the rate parameter $\\lambda$ is changed, the probability of seeing different numbers of events in one interval is changed. The most likely number of events in the interval for each curve is the rate parameter. \n",
    "\n",
    "The Poisson Distribution mass function is used to find the probability of observing a number of events over an interval generated by a Poisson process. Another use of the mass function equation is to find the probability of waiting some time between events.\n",
    "\n",
    "The rate parameter is the only number needed to define the Poisson distribution. As it is a product of events/interval and the interval length it can be changed by adjusting the number of events per interval or by adjusting the interval length.\n",
    "\n",
    "\n",
    "The probability mass function of the Poisson distribution shows the probability of a number of events occurring in an interval with different rate parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-random number generators (PRNG's) and seeds\n",
    "\n",
    "Computer programs produce outputs based on inputs and according to a set of predetermined rules. Pseudorandom numbers are generated in a sequence according to some **deterministic algorithm** from an input called a **seed** which is a number that is used to initialise the pseudorandom number generator. The seed used is typically the time in milliseconds on the computer when the code was run and is used as the starting point of the process.\n",
    "\n",
    "According to [statisticshowto](https://www.statisticshowto.datasciencecentral.com/random-seed-definition/), a random seed specifies the start point when a computer generates a random number. The random seed can be any number but it usually comes from seconds on the computer system's clock which counts in seconds from January 1, 1970.  (known as Unix time). This ensures that the same random sequence won't be repeated unless you actually want it to. \n",
    "\n",
    "Pseudo random number generators can be **seeded** which makes them **deterministic**. To recreate the exact same sequence of random numbers, then you can just explicitly supply the seed as an input to the random number generator. This means that while the numbers generated look random they are not truly random but **pseudorandom**. These pseudorandom numbers  contain no real randomness at all - randomness is just being imitated - but they can take the role of random numbers for certain applications.\n",
    "\n",
    "If you reinitialise a random number generator with the same seed, the default seed is ignored and the same sequence of pseudorandom numbers will be produced. \n",
    "\n",
    "This all means that the outputs can be repeated by following the same set of steps and given the same inputs.  Therefore if you know this **seed** then you can predict the next number to be generated in a sequence.  Pseudorandom number generators should therefore not be used for cryptographic purposes because their predictability could be used to break the encryption but there are times when the exact same sequences of numbers may be required. \n",
    "\n",
    "Psuedorandom numbers are suitable for purposes such as simulating datasets, testing machine learning algorithms etc as well as ensuring reproducibility of code for code sharing, teaching and demonstration purposes. Computer random number generation  algorithms are based on patterns which generate numbers that follow particular **probability distributions**. Setting a seed will produce the same sequence of random numbers each time. \n",
    "\n",
    "\n",
    "According to [pynative.com](https://pynative.com/python-random-seed/) \n",
    ">generally the seed value is the previous number generated by the generator. However, When the first time you use the random generator, there is no previous value. So by-default current system time is used as a seed value.\n",
    " \n",
    "\n",
    "There are many different ways to generate pseudo-random numbers. Python uses the **Mersenne Twister** as the core generator. According to [wikipedia](https://en.m.wikipedia.org/wiki/Mersenne_Twister), the Mersenne Twister is  a pseudorandom number generator (PRNG) and is by far the most widely used general-purpose PRNG whose name derives from the fact that its period length is chosen to be a Mersenne prime (a prime number that is one less than a power of two. That is, it is a prime number of the form Mn = 2n − 1 for some integer n.).\n",
    "\n",
    "***\n",
    "[Khan academy random vs pseudorandom number generators](https://www.khanacademy.org/computing/computer-science/cryptography/crypt/v/random-vs-pseudorandom-number-generators).\n",
    "\n",
    "Here are some notes from watching the above video which gives a very good overview of using seeds with the prngs.\n",
    "\n",
    "There are truly random fluctuations everywhere in the physical world and truly random numbers could be generated by measuring or sampling this noise such as the electric current of tv static over time. A **random walk** can visualise this random sequence where a path is drawn that changes direction according to each number. There would be no pattern at all in a random walk as the next point is always unpredictable. Random processes are nondeterministic since they are impossible to determine in advance whereas machines are deterministic because their operation is predictable and repeatable.\n",
    "\n",
    "In 1946 while involved in running computations for the military, John Neumann required quick access to randomly generated numbers that could be repeated if necessary but as the computer of the time had very limited memory it could not store long random sequences. Nuemann therefore developed an algorithm to mechanically simulate the scrambling aspect of randomness as follows.\n",
    "First a truly random numbers called the 'seed' (which could come from measurement of noise or the current time in milliseconds) is selected which is then provided as input to a very simple calculation where the seed is multiplied by itself, the middle of this output becomes the seed for the next step and the process repeated as many times as required. This was called the \"middle-squares\" method and was the first pseudorandom number generator. The randomness of the seed depends only on the randomness of the initial seed only and the same seed will generate the same sequence.\n",
    "\n",
    "The difference between a random generated versus a pseudorandomly generated sequence is that eventually the pseudorandom sequence will repeat when the algorithm reaches a seed it has previously used. The length before the pseudorandom sequence repeats is called the **period** and the period is strictly limited by the length of the initial seed. \n",
    "The longer the length of the initial seed the longer the period so a 4 digit seed will produce a longer period of unrepeating sequences than a 3 digit seed which is will produce a longer period than a two digit seed. \n",
    "The difference between a pseudorandom generated sequence and a truy random sequence is that there are many sequences that cannot occur in a pseudorandom sequence.  \n",
    "A 20 digit pseudorandom sequence generated from a 4-digit seed is equivalent to a uniform selection from 10,000 possible intial seeds so that only 20,000 different sequences can be generated. when we move from random to pseudorandom shifts the key space is shrunk into a much smaller seed-space.\n",
    "For a pseudorandom sequence to be indistinguishable from a randomly generated sequence, it must be impractical for a computer to try all seeds and look for a match. There is an important distinction in computer science between what is possible versus what is possible in a reasonable amount of time. With pseudorandom generators the security increases as the length of the seed increases. If the most powerful computer would take hundreds of years to run through all seeds then we can safely assume its practically secure instead of perfectly secure. As computers get faster the seed size must increase accordingly. \n",
    "Instead of having to share the entire random shift sequence in advance, you can share the relatively short random seed and expand it into the same random looking sequence when needed. \n",
    "\n",
    "***\n",
    "\n",
    "In summary, random (pseudorandom) numbers are drawn from a probability distribution. The numbers generated depend on the *seed* used and are generated according to some deterministic algorithm from that seed. The numbers that are output depend on the algorithm and the input seed.ß"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
